---
title: "Split apply combine ..."
author: "Oscar Aguilar"
topic: "02"
layout: post
root: ../../../
---

## Background:

The `plyr` package has by now been replaced by other, even faster packages, but the idea of *Split, apply, combine* is as relevant as ever.

Read the paper [The Split-Apply-Combine Strategy for Data Analysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley Wickham.


Write a blog post addressing the questions: 

1. **Which (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient - state why or why not?**. 

There are some base `R` functions that support the split-apply-combine strategy such as `subset()`, `split()`, `by()`, `apply()`, `sapply()`, `lapply()`, `tapply()`, `aggregate()`, `rbind()`, and `cbind()`. These functions can tackle any task  as `plyr`. However, in some scenarios, these functions can take slow down your program when they are using in big loops.

My personal opinion is that the base `R` function mentioned in the previous paragraph are sufficient because they get the job done. On the other hand, from the computing time, it's better to use function from `plyr` such as `ddply`. Also, these function are more intuite, which makes your code easier to read/follow when share with others. 



2. **Using a dataset of your choice, show (by including the split-apply-combine command(s) in your answer) how you can use the split-apply-combine strategy for a part of the data analysis.**




