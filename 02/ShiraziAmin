---
title: "Blog 2:  Split-Apply-Combine Strategy for Data Analysis"
author: "Amin Shirazi"
topic: "02"
layout: post
root: ../../../
---


1. ** Which (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient - state why or why not?.**
There are quite many R built-in (or base R) specialized tools to split data into pieces, apply some function to each individual piece and finally combine back together whatever the results are. These are the family of `apply` functions such as `apply`, `lapply`, `sapply`, `rep`, `mapply`, `aggregate`, `sweep` etc. These functions are used to manipulate pieces of data from matrices, arrays, lists and dataframes in a repetitive way. These function work simply and can consider only one aspect of the data summary at a time. 

In my opinion, these functions are much nicer and more straightforward than writing one's own codes, and they are readable and easy to catch by one look. So, in most cases they are my favorites to easily use because I can remember how they function even months or years later. The disadvatange of these base R functions is that they do not always give us the best solutions possible. One case is that we cannot manipulate  what output to get and what our desired dimensions are for the output. However, with `plyr` package we have more options for the input and output of our data based on different split-apply-combine strategies. 


2. **Using a dataset of your choice, show (by including the split-apply-combine command(s) in your answer) how you can use the split-apply-combine strategy for a part of the data analysis **

The data set is acute toxicity experiments data to conduct an analysis first using a generalized linear model with binomial random component and different link function. AS a part of the analysis, it is required to fit the two glm model to the two series of the data set called `s1` and `s2`. The data set is as follow:
```{r, echo=FALSE}
library(devtools)
library(plyr)
series <- rep(1:2, each = 8)
no_insects <- c(29,30,28,27,30,31,30,29,
                30,30,34,29,33,28,32,31)
CS2mg <- rep(c(49.06,52.99,56.91,60.84,64.76,68.69,72.61,76.54), times = 2)
pct_kill <- c(6.9,23.3,32.9,51.9,76.7,93.6,96.7,100,
              13.3,20,26.5,48.3,87.9,85.7,100,100)

# Adjustments for data analysis
pct_kill <- pct_kill / 100
log_CS2mg <- log(CS2mg)

# Create full data frame
bliss_data <- data.frame(series, no_insects, log_CS2mg ,
                         pct_kill, no_kill = round(no_insects * pct_kill))
print(bliss_data)
```
In order to avoid repeating fitting different models to the data, we can use the `plyr` package to fit the  glm to the two series by defining a list of the two seris and then applying the funcion `llpy` to get a list of coefficients, residuals and fitted values as well as the plots for the fitted values. This can be done faster this  way. The advantage of using split-combine strategy is to get a list of all desired output by applying the split-combine functions. 

```{r}
glmmodel<- function(data){ 
  out<-glm(cbind(no_kill, no_insects-no_kill) ~ log_CS2mg, data = data,
                    family = binomial(link = "logit"))
  return( list(out$coefficients, out$residuals, out$fitted.values,
  plot(data$log_CS2mg[1:8], data$pct_kill[1:8]),
  lines(data$log_CS2mg[1:8], out$fitted.values, col = "red")
  ))
  }

data<-list(bliss_data[1:8,], bliss_data[9:16,])
llply(.data = data, .fun = glmmodel)
```







